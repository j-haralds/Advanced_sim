{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook for Project 1\n",
    "\n",
    "_Jonatan Haraldsson_ [jonhara@chalmers.se](mailto:jonhara@chalmers.se)\n",
    "\n",
    "_Jesper Noord_ [noord@chalmers.se](mailto:noord@chalmers.se)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# relevant modules for this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import emcee\n",
    "import corner\n",
    "import scipy\n",
    "from scipy.stats import gamma, invgamma, t, norm, norminvgauss, mode, uniform\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import sklearn\n",
    "import scipy.constants as const\n",
    "\n",
    "\n",
    "# LaTeX font\n",
    "plt.style.use('default')\n",
    "plt.rc('text', usetex = True)\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "font_size = 16\n",
    "plt.rcParams['font.size'] = font_size\n",
    "\n",
    "c = const.speed_of_light *1e-3\n",
    "G = const.gravitational_constant\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the data from SCP 2.1 dataset and exploring data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = np.genfromtxt('SCPUnion2.1_mu_vs_z.txt')\n",
    "df = pd.DataFrame(data_[:,1:5])  # only keep z, mu, mu_err\n",
    "df.columns = [\"z\", \"mu\", \"mu_err\", \"unknown\"]\n",
    "\n",
    "\n",
    "z = np.array(df['z'])\n",
    "mu = np.array(df['mu'])\n",
    "mu_err = np.array(df['mu_err'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2,figsize=(12,8))\n",
    "ax[0,0].hist(z, bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "ax[0,0].set_xlabel('Redshift $z$')\n",
    "ax[0,0].set_ylabel('Number of SNe Ia')\n",
    "ax[0,0].set_title('Distribution of Redshift in SCP 2.1 Dataset')\n",
    "ax[0,1].hist(mu, bins=50,density=True,color='tab:red',alpha=0.5,edgecolor='black')\n",
    "ax[0,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[0,1].set_ylabel('Disttibution for $\\\\mu$')\n",
    "ax[0,1].set_title('Distribution of Magnitude in SCP 2.1 Dataset')\n",
    "ax[0,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[0,1].set_ylabel('Disttibution for $\\\\mu$')\n",
    "ax[0,1].set_title('Distribution of Magnitude in SCP 2.1 Dataset')\n",
    "\n",
    "\n",
    "ax[1,0].hist(df['unknown'], bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "ax[1,0].set_xlabel('Redshift diff $\\\\delta z$')\n",
    "#ax[0,0].set_ylabel('Number of SNe Ia')\n",
    "#ax[0,0].set_title('Distribution of Redshift in SCP 2.1 Dataset')\n",
    "ax[1,1].hist(mu_err, bins=50,density=True,color='tab:red',alpha=0.5,edgecolor='black')\n",
    "ax[1,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[1,1].set_ylabel('Distibution for $\\\\mu$')\n",
    "ax[1,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[1,1].set_ylabel('Distibution for $\\\\mu$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.errorbar(z,mu,yerr=mu_err,color='tab:blue',alpha=0.5)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.errorbar(z,mu,yerr=mu_err,color='tab:blue',alpha=0.5,fmt='o',markersize=4,elinewidth=1,capsize=2)\n",
    "plt.xlabel('Redshift $z$')\n",
    "plt.ylabel('Distance Modulus $\\\\mu$')\n",
    "plt.title('All $z$ values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering in the small-$z$ region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = df['z'] < 0.5\n",
    "z_low = np.array(df['z'][i])\n",
    "mu_low = np.array(df['mu'][i])\n",
    "mu_err_low = np.array(df['mu_err'][i])\n",
    "unknown_low = np.array(df['unknown'][i])\n",
    "\n",
    "fig,ax = plt.subplots(2,2,figsize=(12,8))\n",
    "ax[0,0].hist(z_low, bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "ax[0,0].set_xlabel('Redshift $z$')\n",
    "ax[0,0].set_ylabel('Number of SNe Ia')\n",
    "ax[0,0].set_title('Distribution of Redshift in SCP 2.1 Dataset')\n",
    "ax[0,1].hist(mu_low, bins=50,density=True,color='tab:red',alpha=0.5,edgecolor='black')\n",
    "ax[0,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[0,1].set_ylabel('Disttibution for $\\\\mu$')\n",
    "ax[0,1].set_title('Distribution of Magnitude in SCP 2.1 Dataset')\n",
    "ax[0,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[0,1].set_ylabel('Disttibution for $\\\\mu$')\n",
    "ax[0,1].set_title('Distribution of Magnitude in SCP 2.1 Dataset')\n",
    "\n",
    "\n",
    "ax[1,0].hist(mu_err_low, bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "ax[1,0].set_xlabel('Redshift diff $\\\\delta z$')\n",
    "#ax[0,0].set_ylabel('Number of SNe Ia')\n",
    "#ax[0,0].set_title('Distribution of Redshift in SCP 2.1 Dataset')\n",
    "ax[1,1].hist(unknown_low, bins=50,density=True,color='tab:red',alpha=0.5,edgecolor='black')\n",
    "ax[1,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[1,1].set_ylabel('Distibution for $\\\\mu$')\n",
    "ax[1,1].set_xlabel('Magnitude $\\\\mu$')\n",
    "ax[1,1].set_ylabel('Distibution for $\\\\mu$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.errorbar(z_low,mu_low,yerr=mu_err_low,color='tab:blue',alpha=0.5,fmt='o',markersize=4,elinewidth=1,capsize=2,label='Data points')\n",
    "plt.xlabel('Redshift $z$')\n",
    "plt.ylabel('Distance Modulus $\\\\mu$')\n",
    "plt.title('Low $z$ region')\n",
    "plt.plot(np.sort(z_low),low_z_model(70,np.sort(z_low),0.1),color='tab:red',label='$H_0 = 70$, $q_0 = 0.5$',lw = 3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining some useful functions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_to_d(mu):\n",
    "    return 10**((mu - 25) / 5)  # in Mpc\n",
    "\n",
    "def d_to_mu(d):\n",
    "    if all(i <= 0  for i in d) == False:\n",
    "        mu = 5 * np.log10(d) + 25\n",
    "    else:\n",
    "        print(f'MIN DISTANCE: {np.min(d)}')\n",
    "        raise ValueError(\"Distance must be positive.\")\n",
    "    return mu\n",
    "\n",
    "def rho_crit(H):\n",
    "    return 3 * H**2 / (8 * np.pi * G)\n",
    "\n",
    "def get_Om_lam(lam,H):\n",
    "    return lam / (3 * H**2)\n",
    "\n",
    "def get_Om_M(lam,H,Om_k = None):\n",
    "    if Om_k is not None:\n",
    "        return 1 - Om_k - get_Om_lam(lam,H)\n",
    "    else:\n",
    "        return 1 - get_Om_lam(lam,H)\n",
    "    \n",
    "def get_q0(Om_M,Om_lam):\n",
    "    return Om_M / 2 - Om_lam\n",
    "\n",
    "def get_dl(H_0,z,q_0):\n",
    "    d = (c / H_0) * (z + (1-q_0) * z**2/2)\n",
    "    return d\n",
    "\n",
    "def low_z_model(H,z,q0):\n",
    "    model = d_to_mu(get_dl(H,z,q0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(get_dl(70,z_low,0.5), bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "plt.xlabel('$d_L$ [Mpc]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nig_log(th,s2,mu0,Sigma0,alpha,beta):\n",
    "\n",
    "    if alpha<=0:\n",
    "        print('error alpha<=0')\n",
    "        return 0\n",
    "    if beta<=0:\n",
    "        print('error beta<=0')\n",
    "        return 0\n",
    "\n",
    "    NIG_log = norm.logpdf(th,loc=mu0,scale=np.sqrt(s2)*np.sqrt(Sigma0))+invgamma.logpdf(s2,a=alpha,scale=beta)\n",
    "\n",
    "    return NIG_log\n",
    "    \n",
    "# helper function to convert the IG mean,mode to alpha,beta\n",
    "def mean_mode_2_IG_alpha_beta(mean,mode):\n",
    "    alpha = (mode + mean)/(mean-mode)\n",
    "    beta = (2 * mode * mean)/(mean-mode)\n",
    "    return alpha, beta\n",
    "\n",
    "# helper function to convert the G mean,variance to alpha,beta\n",
    "def mean_variance_2_G_alpha_beta(mean,variance):\n",
    "    alpha = mean**2/variance\n",
    "    beta = variance/mean\n",
    "    return alpha, beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to use $$d_L=\\frac{c}{H_0}\\left(z + \\frac{1}{2}(1-q_0)z^2\\right)$$ in the small-$z$ regime $(z < 0.5)$ to extract a joint probability\n",
    "distribution for $H_0$ and $q_0$. You should use data weights proportional to the measurement errors,\n",
    "and an inverse gamma prior for the unknown error scale $Ïƒ^2$. You can use e.g. uniform priors for\n",
    "$H0$ and $q0$ if you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\log$-Prior, $\\log$-Likelihood and $\\log$-posterior \n",
    "\n",
    "Prior is given by $$\\mathcal{U}_H[H_{min},H_{max}]\\times\\mathcal{U}_q[q_{min},q_{max}]\\times \\mathcal{NIG}(\\alpha,\\beta,\\sigma^2)$$\n",
    "\n",
    "Likelihood's given by $$\\cancel{\\left( \\frac{1}{2\\pi} \\right)^{N_d/2}} \\frac{1}{|W|^{-1/2}} \\exp \\left[ -\\frac{1}{2} (\\mathcal{D} - \\boldsymbol{y}_{model})^{T} W (\\mathcal{D} - \\boldsymbol{y}_{model}) \\right],$$ where $$W=\\frac{1}{N_d}\\begin{bmatrix} 1/\\sigma^2_1 & \\cdots & 0 \\\\ \\vdots& \\ddots & 0 \\\\ 0 & & 1/\\sigma_{N_d}^2 \\end{bmatrix}\\quad\\text{and}\\quad\\mathcal{D} = \\mu \\quad \\text{and}\\quad \\boldsymbol{y}_{model}=5\\log_{10}\\left[\\frac{c}{H_0}\\left(z + \\frac{1}{2}(1-q_0)z^2\\right)\\right] + 25$$\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, z, mu, sig_mu):\n",
    "    '''\n",
    "    \n",
    "    z - found in data frame\n",
    "    mu - found in data frame\n",
    "    sig_m - found in data frame\n",
    "    '''\n",
    "    H0 = theta[0]#.flatten()\n",
    "    q0 = theta[1]#.flatten()\n",
    "    s2 = sig_mu# + theta[2]**2\n",
    "    Nd = len(mu)\n",
    "    w = 1 / s2 * (1 / Nd)\n",
    "    W = np.diag(w)\n",
    "    #print(np.max(W))\n",
    "    y = mu\n",
    "    model = d_to_mu(get_dl(H0,z,q0))\n",
    "    \n",
    "    log_like = -0.5 * (y - model).T @ W @ (y - model)/theta[2] + 0.5 * np.linalg.det(W) - Nd * (np.sum(np.log(2 * np.pi * theta[2]))/2)\n",
    "\n",
    "    return log_like#, y[0], model[0]\n",
    "\n",
    "def log_prior(theta,a0, b0, H0_lims = [50,100], q0_lims = [-2,2]):\n",
    "\n",
    "    H0 = theta[0]#.flatten()\n",
    "    q0  = theta[1]#.flatten()\n",
    "    sig2 = theta[2]#.flatten()\n",
    "\n",
    "    H0_min = H0_lims[0]; H0_max = H0_lims[1]\n",
    "    q0_min = q0_lims[0];  q0_max = q0_lims[1]\n",
    "\n",
    "    log_H = uniform.logpdf(H0, loc=H0_min, scale=H0_max - H0_min)\n",
    "\n",
    "    log_q = uniform.logpdf(q0, loc = q0_min, scale = q0_max - q0_min)\n",
    "\n",
    "    log_th = log_q + log_H\n",
    "\n",
    "    log_IG = invgamma.logpdf(sig2,a=a0, scale=b0)  \n",
    "\n",
    "    #log_N  = norm.logpdf(0,loc=mu0,scale=np.sqrt(sig2)*np.sqrt(Sigma_0[0]))\n",
    "    lp = log_th + log_IG# + log_N\n",
    "    \n",
    "    return lp\n",
    "\n",
    "\n",
    "def log_posterior(theta, z, mu, sig_m, a0, b0):\n",
    "\n",
    "    log_like = log_likelihood(theta, z, mu, sig_m)\n",
    "    log_pri = log_prior(theta, a0, b0)\n",
    "    \n",
    "    log_post = log_like + log_pri\n",
    "    if np.isnan(log_post):\n",
    "        return -np.inf\n",
    "    \n",
    "    return log_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IG_mean = 10\n",
    "IG_mode = 0.5\n",
    "a0, b0  = mean_mode_2_IG_alpha_beta(IG_mean,IG_mode)\n",
    "\n",
    "print(log_prior(np.array([70,0.5,0.05**2]),a0,b0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H0_grid = np.linspace(50,100,len(z_low))\n",
    "q0_grid = np.linspace(-5,5,len(H0_grid))\n",
    "\n",
    "H0, q0 = np.meshgrid(H0_grid,q0_grid)\n",
    "\n",
    "HQ_grid = np.dstack((H0,q0))\n",
    "grid = HQ_grid.reshape(-1,2)\n",
    "\n",
    "z = z_low\n",
    "mu = mu_low\n",
    "sig = mu_err_low\n",
    "\n",
    "#z = unknown_low\n",
    "\n",
    "n = 0\n",
    "like = np.zeros((len(q0_grid),len(H0_grid)))\n",
    "sum_like = 0\n",
    "for q_i,i in zip(q0_grid, range(len(q0_grid))):\n",
    "    for H_i,j in zip(H0_grid, range(len(H0_grid))):\n",
    "        lh = log_likelihood([H_i,q_i,0.5], z, mu, sig)\n",
    "        like[i,j] = np.exp(lh)\n",
    "\n",
    "\n",
    "\"\"\"post_pdf = np.zeros_like(grid)\n",
    "for th_idx, th_val in enumerate(H0):\n",
    "    for s2_idx, s2_val in enumerate(q0):\n",
    "        post_pdf[s2_idx][th_idx] = log_posterior([th_val,s2_val], z, mu, sig)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "plt.contourf(H0, q0, like, levels=200, cmap='Blues')#,alpha=0.5)\n",
    "plt.xlabel('$H_0$ [km/s/Mpc]')\n",
    "plt.ylabel('$q_0$')\n",
    "\n",
    "#print(log_posterior(th,z,mu,sig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(H0, q0, like, levels=200, cmap='Blues')#,alpha=0.5)\n",
    "plt.colorbar(label='Likelihood')\n",
    "plt.xlabel('$H_0$ [km/s/Mpc]')\n",
    "plt.ylabel('$q_0$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_grid = np.linspace(10,150,len(z_low))\n",
    "q0_grid = np.linspace(-15,15,len(H0_grid))\n",
    "\n",
    "H0, q0 = np.meshgrid(H0_grid,q0_grid)\n",
    "\n",
    "HQ_grid = np.dstack((H0,q0))\n",
    "grid = HQ_grid.reshape(-1,2)\n",
    "\n",
    "z = z_low\n",
    "mu = mu_low\n",
    "sig = mu_err_low\n",
    "\n",
    "n = 0\n",
    "pri = np.zeros((len(q0_grid),len(H0_grid)))\n",
    "\n",
    "for q_i,i in zip(q0_grid, range(len(q0_grid))):\n",
    "    for H_i,j in zip(H0_grid, range(len(H0_grid))):\n",
    "        lp = log_prior([H_i,q_i,0.1], a0, b0)\n",
    "        pri[i,j] = np.exp(lp)\n",
    "\n",
    "\n",
    "plt.contourf(H0, q0, pri, levels=200, cmap='Blues')#,alpha=0.5)\n",
    "plt.xlabel('$H_0$ [km/s/Mpc]')\n",
    "plt.ylabel('$q_0$')\n",
    "\n",
    "# prior_pdf = np.zeros((len(H0_grid),len(q0_grid)))\n",
    "# for H_i,H_val in enumerate(H0_grid):\n",
    "#     for q_i,q_val in enumerate(q0_grid):\n",
    "#         prior_pdf[q_i][H_i] = log_posterior([H_val,q_val,0.05**2],z,mu,sig, mu0, Sigma0,a0,b0)\n",
    "\n",
    "# plt.contourf(H0, q0, np.exp(prior_pdf) , levels=200, cmap='Blues')#,alpha=0.5)\n",
    "#print(log_posterior(th,z,mu,sig))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_grid = np.linspace(10,150,len(z_low))\n",
    "sigma_sample = np.linspace(0,10,len(H0_grid))\n",
    "\n",
    "H0, sigm = np.meshgrid(H0_grid,sigma_sample)\n",
    "\n",
    "\n",
    "z = z_low\n",
    "mu = mu_low\n",
    "sig = mu_err_low\n",
    "\n",
    "n = 0\n",
    "pri = np.zeros((len(sigma_sample),len(H0_grid)))\n",
    "\n",
    "for s,i in zip(sigma_sample, range(len(sigma_sample))):\n",
    "    for H_i,j in zip(H0_grid, range(len(H0_grid))):\n",
    "        lp = log_prior([H_i,0.5,s], a0, b0)\n",
    "        pri[i,j] = np.exp(lp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(H0, sigm, pri, levels=200, cmap='Blues')#,alpha=0.5)\n",
    "plt.xlabel('$H_0$ [km/s/Mpc]')\n",
    "plt.ylabel('$\\sigma^2$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in sigma_sample:\n",
    "    lp = log_prior([70,0.5,s], a0, b0)\n",
    "    plt.scatter(s,np.exp(lp),c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q0_grid,np.exp(log_posterior([70,q0_grid],z,mu,sig)))\n",
    "plt.show()\n",
    "\n",
    "print(np.min(log_posterior([H0_grid,q0_grid],z,mu,sig)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC sampling\n",
    "Here we go again!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_MCMC(q0_lims, H0_lims, post,x, y, sigma ,nwalkers, burninproc =10 , iterations = 10000):\n",
    "    \"\"\"\n",
    "    Sets up an MCMC sampler with initial positions for the walkers.\n",
    "\n",
    "    Args:\n",
    "        theta_0_lims (list): Minimum and maximum boundary for starting position in theta0.\n",
    "        theta_1_lims (list): Minimum and maximum boundary for starting position in theta1.\n",
    "        x (array): Independent data.\n",
    "        y (array): Dependent data.\n",
    "        post (callable): Function to compute the log-posterior or log-likelihood.\n",
    "        nwalkers (int): Number of MCMC walkers.\n",
    "\n",
    "    Returns:\n",
    "        sampler (emcee.EnsembleSampler): Initialized MCMC sampler object.\n",
    "    \"\"\"\n",
    "    \n",
    "    ndim = 3  # Since theta has three parameters: [intercept, slope,sigma]\n",
    "\n",
    "    rng = np.random.default_rng(seed = 1337)\n",
    "\n",
    "\n",
    "    q   = rng.uniform(q0_lims[0],q0_lims[1],size = nwalkers)\n",
    "    H   = rng.uniform(H0_lims[0],H0_lims[1],size = nwalkers)\n",
    "    sig = rng.uniform(0.1,10,size = nwalkers)\n",
    "\n",
    "    p0 = np.vstack((q,H,sig)).T\n",
    "\n",
    "    burnin = int(burninproc*iterations/100)\n",
    "\n",
    "    # Set up the MCMC sampler with the log posterior function\n",
    "    sampler_post = emcee.EnsembleSampler(nwalkers, ndim, post, args = (x, y, sigma, a0, b0))\n",
    "    new_pos, prob, state = sampler_post.run_mcmc(p0, burnin, progress=True)\n",
    "\n",
    "    run = sampler_post.run_mcmc(new_pos, iterations)#, progress=True)\n",
    "    samples = sampler_post.get_chain(discard = burnin,flat = True)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = z_low\n",
    "y = mu_low\n",
    "sig = mu_err_low\n",
    "\n",
    "H0_lims = [50,90]\n",
    "q0_lims = [-2,2]\n",
    "\n",
    "samples = samples_MCMC(H0_lims,q0_lims,log_posterior,x,y,\n",
    "                                 sigma = sig,iterations=int(5e3),nwalkers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of samples',len(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = corner.corner(samples, labels=[r\"$H_0$\", r\"$q_0$\",r\"$\\sigma^2$\"], color='k',\n",
    "                show_titles=True, bins=30, plot_contours=True, plot_datapoints=True, \n",
    "                plot_density=True,quantiles=[0.16,0.5,0.84])#,truths = [intercept,slope,sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(x, factor=0.02):\n",
    "    \"\"\"\n",
    "    Return the running mean of N element in a list.\n",
    "\n",
    "    Args:\n",
    "        x (ndarray): The list of elements,\n",
    "        factor (float): The factor to multiply the length of the list by.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: The running mean.\n",
    "    \"\"\"\n",
    "    it, walker = x.shape\n",
    "    N = int(factor * it)\n",
    "    average = np.zeros((it - N+1,walker))\n",
    "    #print(average.shape)\n",
    "    for i in range(walker):\n",
    "        cumsum = np.cumsum(np.insert(x[:,i], 0, 0))\n",
    "        #print((cumsum[N:] - cumsum[:-N]).shape)\n",
    "        average[:,i] = ((cumsum[N:] - cumsum[:-N]) / float(N))\n",
    "   # average = np.sum(average,axis=1)\n",
    "\n",
    "    return average\n",
    "\n",
    "\n",
    "def trace_plotter(samples):\n",
    "    ndim = samples.shape[1]\n",
    "    fig, axes = plt.subplots(ndim, figsize=(4*ndim, 3*ndim), sharex=True)\n",
    "    labels = [r\"$H_0$\", r\"$q_0$\", r\"$\\sigma^2$\"]\n",
    "    mean = running_mean(samples)\n",
    "    for i in range(3):\n",
    "        ax = axes[i]\n",
    "        ax.plot(samples[:, i], \"k\", alpha=0.3)\n",
    "        ax.plot(np.arange(len(mean)), mean[:,i], color='tab:red')\n",
    "        ax.set_ylabel(labels[i])\n",
    "\n",
    "    axes[-1].set_xlabel(\"step number\");\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_plotter(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_dist = samples[:,0]\n",
    "q_dist = samples[:,1]\n",
    "mu = low_z_model(H_dist,1,q_dist)\n",
    "plt.hist(mu,bins=50,density=True,color='tab:blue',alpha=0.5,edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "Nsamp = 1000\n",
    "idx = random.sample(range(0,len(samples)),Nsamp)\n",
    "\n",
    "z_ = np.linspace(np.min(df['z']),np.max(df['z']),1000)\n",
    "\n",
    "#plt.scatter(df['z'],df['mu'],c='k',alpha=0.1\n",
    "for i in idx: \n",
    "    H = samples[i,0]; q = samples[i,1]\n",
    "    mu_= low_z_model(H,z_,q) +  np.random.normal(0,np.sqrt(samples[i,2]))\n",
    "    plt.plot(z_,mu_,alpha=0.05,color = 'tab:blue',lw = 0.5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
